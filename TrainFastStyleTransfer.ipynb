{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainFastStyleTransfer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlosdg/TrainStyleTransfer/blob/master/TrainFastStyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jf4cIi4Ei0Un",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Fast Style Transfer for a ml5js model\n",
        "\n",
        "We are just following the guide in the [_training-styletransfer_ repository of ml5](https://github.com/ml5js/training-styletransfer) but in google colab. This was done in January 25, 2019. We say this because time goes on and you may find some differences due to different versions. At this time the repository has 16 commits and we used the model successfully on ml5js version 0.1.1\n",
        "\n",
        "__The first step is very important: we need to set the environment to use the GPU__. Go to the `Runtime` tab (up in the window, below the notebook name) and select `Change runtime type`.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img\n",
        "       src=\"https://drive.google.com/uc?export=view&id=1uGKJdbcWIV_ym2zi63Z-TfWLAcQyy4c2\"\n",
        "       alt=\"Screenshot showing where the change runtime type is\"\n",
        "       width=\"360\"\n",
        "  />\n",
        "</p>\n",
        "\n",
        "There select `GPU` and click `Save`.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img\n",
        "       src=\"https://drive.google.com/uc?export=view&id=1hucS-ZADr3ucmVt9U8vicNNjxZ9U4d2_\"\n",
        "       alt=\"Screenshot showing the notebook settings with GPU selected as hardware accelerator option\"\n",
        "       width=\"360\"\n",
        "  />\n",
        "</p>\n",
        "\n",
        "\n",
        "Now that we are ready to use the GPU we clone the repository:"
      ]
    },
    {
      "metadata": {
        "id": "DdwxMbTF36Mr",
        "colab_type": "code",
        "outputId": "86d3fc6a-ea0a-4b0b-b227-49864678f78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ml5js/training_styletransfer.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'training_styletransfer'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Total 83 (delta 0), reused 0 (delta 0), pack-reused 83\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7jjshJKwjinI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Download & unzip the COCO dataset\n",
        "\n",
        "Now we download the dataset of images that will be used in training. Note that this will take some minutes to finish.\n",
        "\n",
        "In the guide we are told to execute `bash setup.sh` but the unzip command is verbose and annoying (for us at least), so the following commands are the same ones in `setup.sh` but with a quiet unzip (note the `-qq` option) and without the `mkdir` because the repository already have the folders created"
      ]
    },
    {
      "metadata": {
        "id": "05O8OzM54XtI",
        "colab_type": "code",
        "outputId": "f7d06bb4-08f3-4c62-c998-6be5b296720c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "source": [
        "!cd training_styletransfer/data && \\\n",
        "wget http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat && \\\n",
        "wget http://msvocds.blob.core.windows.net/coco2014/train2014.zip && \\\n",
        "unzip -qq train2014.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-05 16:26:04--  http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat\n",
            "Resolving www.vlfeat.org (www.vlfeat.org)... 64.90.48.57\n",
            "Connecting to www.vlfeat.org (www.vlfeat.org)|64.90.48.57|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 576042600 (549M) [text/plain]\n",
            "Saving to: ‚Äòimagenet-vgg-verydeep-19.mat‚Äô\n",
            "\n",
            "imagenet-vgg-veryde 100%[===================>] 549.36M  68.7MB/s    in 8.2s    \n",
            "\n",
            "2019-02-05 16:26:12 (66.8 MB/s) - ‚Äòimagenet-vgg-verydeep-19.mat‚Äô saved [576042600/576042600]\n",
            "\n",
            "--2019-02-05 16:26:12--  http://msvocds.blob.core.windows.net/coco2014/train2014.zip\n",
            "Resolving msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)... 52.176.224.96\n",
            "Connecting to msvocds.blob.core.windows.net (msvocds.blob.core.windows.net)|52.176.224.96|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13510573713 (13G) [application/octet-stream]\n",
            "Saving to: ‚Äòtrain2014.zip‚Äô\n",
            "\n",
            "train2014.zip       100%[===================>]  12.58G  20.6MB/s    in 10m 10s \n",
            "\n",
            "2019-02-05 16:36:23 (21.1 MB/s) - ‚Äòtrain2014.zip‚Äô saved [13510573713/13510573713]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3PCpiZe-p0C8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Upload the style image\n",
        "\n",
        "Go to the left pane in here. If it is not already open you should see something like an arrow pointing towards the notebook, click there to open the pane.\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img \n",
        "       alt=\"Screenshot showing the arrow to open the pane\" \n",
        "       src=\"https://drive.google.com/uc?export=view&id=10xRTTEhLkwKgACgsQCoypI9FPqbz-Udw\"\n",
        "       width=\"360\"\n",
        "   />  \n",
        "</p>\n",
        "\n",
        "Once open you should see a `Files` tab. Then you can see the tree directory of the virtual machine. You can also see an `Upload` option\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img \n",
        "       alt=\"Screenshot showing the Files tab and Upload button\" \n",
        "       src=\"https://drive.google.com/uc?export=view&id=10WglV3FgxqoAb9JN4DcAX1BxcgU5NZIZ\"\n",
        "       width=\"360\"\n",
        "   />  \n",
        "</p>\n",
        "\n",
        "Click there and upload your style image (it should be uploaded in the folder as `training_styletransfer` and `sample_data`).\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img \n",
        "       alt=\"Screenshot showing where the style image should be\" \n",
        "       src=\"https://drive.google.com/uc?export=view&id=1JpZnWzRV2suwGeo5bg3BGvUUnj1yvqHL\"\n",
        "       width=\"360\"\n",
        "   />  \n",
        "</p>\n",
        "\n",
        "Make sure that the style image has a reasonable size. We used images with dimensions about 600x300."
      ]
    },
    {
      "metadata": {
        "id": "p-f9mzALpKUv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Run the training script\n",
        "\n",
        "Here you have to __change `style.jpg` with the style image name that you uploaded__ to colab (or have the style name be `style.jpg`).\n",
        "\n",
        "Note that this will take a long time, about 6 to 8 hours. Make sure to come back every now and then to check that virtual machine is still running.\n",
        "\n",
        "We have successfully trained 4 models and with all the available GPU memory for this process we had no problem üëç. But keep in mind that the virtual machines are recycled after 12 hours. So, in our case, after we trained a style we waited for the next day to train another one."
      ]
    },
    {
      "metadata": {
        "id": "5ypMMcwQ5URC",
        "colab_type": "code",
        "outputId": "b1770eca-20fe-4c07-c2f5-dffce8b1f69a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "!cd training_styletransfer && \\\n",
        "python style.py --style ../style.jpg \\\n",
        "  --checkpoint-dir checkpoints/ \\\n",
        "  --model-dir models/ \\\n",
        "  --test images/violetaparra.jpg \\\n",
        "  --test-dir tests/ \\\n",
        "  --content-weight 1.5e1 \\\n",
        "  --checkpoint-iterations 1000 \\\n",
        "  --batch-size 20"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ml5.js Style Transfer Training!\n",
            "Note: This traning will take a couple of hours.\n",
            "Training is starting!...\n",
            "Train set has been trimmed slightly..\n",
            "(1, 338, 600, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "UID: 53\n",
            "Epoch 0, Iteration: 1000, Loss: 13033148.0\n",
            "style: 3350417.0, content:9169216.0, tv: 513515.0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Epoch 0, Iteration: 2000, Loss: 11091828.0\n",
            "style: 2845587.2, content:7921103.0, tv: 325138.03\n",
            "Epoch 0, Iteration: 3000, Loss: 10330670.0\n",
            "style: 2688080.0, content:7378930.5, tv: 263659.94\n",
            "Epoch 0, Iteration: 4000, Loss: 9105090.0\n",
            "style: 2524901.0, content:6344101.5, tv: 236087.89\n",
            "Epoch 1, Iteration: 1000, Loss: 9132523.0\n",
            "style: 2507592.2, content:6404924.0, tv: 220006.78\n",
            "Epoch 1, Iteration: 2000, Loss: 9024319.0\n",
            "style: 2439302.8, content:6379151.0, tv: 205864.92\n",
            "Epoch 1, Iteration: 3000, Loss: 8880954.0\n",
            "style: 2364442.5, content:6319009.0, tv: 197502.44\n",
            "Epoch 1, Iteration: 4000, Loss: 8078439.0\n",
            "style: 2243777.5, content:5651477.0, tv: 183184.39\n",
            "Epoch 1, Iteration: 4139, Loss: 8178244.0\n",
            "style: 2120287.5, content:5859387.5, tv: 198569.2\n",
            "Training complete. For evaluation:\n",
            "    `python evaluate.py --checkpoint checkpoints/ ...`\n",
            "Converting model to ml5js\n",
            "Writing manifest to models/manifest.json\n",
            "Done! Checkpoint saved. Visit https://ml5js.org/docs/StyleTransfer for more information\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EaP1Y0dvpf8K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Zip & Download the model\n",
        "\n",
        "Here we make a zip with the model so we can go to the left pane, and in the `files` tab right click `result.zip` and download it. If you don't see `result.zip` try clicking on the `Update` button next to `Upload` to refresh the `Files` tab"
      ]
    },
    {
      "metadata": {
        "id": "ZbdyBCUmaPH2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "8e96b12f-f33a-461b-adc8-7b6eeaa62fde"
      },
      "cell_type": "code",
      "source": [
        "!zip -r result.zip training_styletransfer/models"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: training_styletransfer/models/ (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_15 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_5 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_42 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_26 (deflated 4%)\n",
            "  adding: training_styletransfer/models/Variable_6 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_24 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_18 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_33 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_13 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_34 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_37 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_25 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_35 (deflated 6%)\n",
            "  adding: training_styletransfer/models/Variable_36 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_1 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_27 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_7 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable (deflated 7%)\n",
            "  adding: training_styletransfer/models/.keep (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_21 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_2 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_28 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_41 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_10 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_44 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_40 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_22 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_38 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_45 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_32 (deflated 6%)\n",
            "  adding: training_styletransfer/models/Variable_20 (deflated 5%)\n",
            "  adding: training_styletransfer/models/Variable_16 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_46 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_19 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_9 (deflated 7%)\n",
            "  adding: training_styletransfer/models/manifest.json (deflated 91%)\n",
            "  adding: training_styletransfer/models/Variable_11 (deflated 5%)\n",
            "  adding: training_styletransfer/models/Variable_31 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_29 (deflated 5%)\n",
            "  adding: training_styletransfer/models/Variable_39 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_47 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_23 (deflated 5%)\n",
            "  adding: training_styletransfer/models/Variable_3 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_43 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_30 (deflated 7%)\n",
            "  adding: training_styletransfer/models/Variable_4 (stored 0%)\n",
            "  adding: training_styletransfer/models/Variable_17 (deflated 5%)\n",
            "  adding: training_styletransfer/models/Variable_14 (deflated 4%)\n",
            "  adding: training_styletransfer/models/Variable_8 (deflated 4%)\n",
            "  adding: training_styletransfer/models/Variable_12 (deflated 7%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}